
#!/usr/bin/env python3
"""
Combinations Analysis - í†µí•© ë°ì´í„° ê´€ê³„ ë¶„ì„ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ ê°„ ê´€ê³„ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
- ìˆ˜ì¹˜í˜• Ã— ìˆ˜ì¹˜í˜•: ìƒê´€ê´€ê³„ ë¶„ì„ (Pearson, Spearman, Kendall)
- ë²”ì£¼í˜• Ã— ë²”ì£¼í˜•: ì—°ê´€ê·œì¹™ ë¶„ì„ (Lift, Cramer's V)
- ë²”ì£¼í˜• Ã— ìˆ˜ì¹˜í˜•: ë¶„ì‚°ë¶„ì„ (ANOVA, eta-squared)
- í…ìŠ¤íŠ¸ ë¶„ì„: ê¸°ë³¸ í…ìŠ¤íŠ¸ í†µê³„
- CLI ì¸í„°í˜ì´ìŠ¤: ëª…ë ¹ì¤„ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
- ë©”ëª¨ë¦¬ ìµœì í™” ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

ì‚¬ìš©ë²•:
    # Python ì½”ë“œì—ì„œ
    from combinations import analyze_combinations
    results = analyze_combinations(df)
    
    # ê³ ê¸‰ ë¶„ì„
    from combinations import AdvancedCombinationsAnalyzer, AnalysisConfig
    config = AnalysisConfig(parallel_processing=True)
    analyzer = AdvancedCombinationsAnalyzer(config)
    results = analyzer.analyze_combinations_advanced(df)
    
    # CLIì—ì„œ ë°”ë¡œ ì‹¤í–‰
    python combinations.py --input data.csv --output results.json
"""

from __future__ import annotations
import sys
import argparse
import json
import time
import logging
import warnings
import hashlib
import threading
from pathlib import Path
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Dict, List, Any, Optional, Tuple, Union
from itertools import combinations
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import pandas as pd

# ì„ íƒì  ì˜ì¡´ì„±
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    warnings.warn("psutilì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.", UserWarning)

try:
    from scipy import stats
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    warnings.warn("scipyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì¼ë¶€ í†µê³„ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.", UserWarning)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class AnalysisConfig:
    """ë¶„ì„ ì„¤ì • í´ë˜ìŠ¤"""
    max_cardinality: int = 50
    top_k: int = 20
    sample_cap: int = 200_000
    min_sample_size: int = 30
    correlation_threshold: float = 0.3
    lift_threshold: float = 1.5
    eta2_threshold: float = 0.1
    parallel_processing: bool = True
    max_workers: int = 4
    enable_caching: bool = True
    cache_dir: str = ".analysis_cache"
    memory_optimization: bool = True
    text_analysis: bool = False  # ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ í´ë˜ìŠ¤"""
    start_time: float
    end_time: float = None
    memory_usage: Dict[str, float] = None
    cpu_usage: float = None
    operation_count: int = 0
    error_count: int = 0

    @property
    def duration(self) -> float:
        return (self.end_time - self.start_time) if self.end_time else 0

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""

    def __init__(self):
        self.metrics_history: List[PerformanceMetrics] = []
        self.is_monitoring = False
        self.monitor_thread = None

    @contextmanager
    def track_operation(self, operation_name: str):
        """ì‘ì—… ìˆ˜í–‰ ì‹œê°„ ì¶”ì """
        start_time = time.time()
        start_memory = psutil.virtual_memory().used if HAS_PSUTIL else 0

        try:
            yield
        finally:
            end_time = time.time()
            end_memory = psutil.virtual_memory().used if HAS_PSUTIL else 0

            metrics = PerformanceMetrics(
                start_time=start_time,
                end_time=end_time,
                memory_usage={
                    'start': start_memory,
                    'end': end_memory,
                    'delta': end_memory - start_memory
                } if HAS_PSUTIL else {'start': 0, 'end': 0, 'delta': 0},
                cpu_usage=psutil.cpu_percent(interval=0.1) if HAS_PSUTIL else 0
            )

            self.metrics_history.append(metrics)
            logger.info(f"{operation_name} ì™„ë£Œ: {metrics.duration:.2f}ì´ˆ")

    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        if not self.metrics_history:
            return {"error": "no_metrics_available"}

        total_duration = sum(m.duration for m in self.metrics_history)
        avg_memory_delta = sum(m.memory_usage['delta'] for m in self.metrics_history) / len(self.metrics_history)

        return {
            "total_operations": len(self.metrics_history),
            "total_duration": total_duration,
            "average_duration": total_duration / len(self.metrics_history),
            "average_memory_delta": avg_memory_delta,
            "memory_efficiency": "good" if avg_memory_delta < 50*1024*1024 else "needs_optimization"
        }

class MemoryOptimizer:
    """ë©”ëª¨ë¦¬ ìµœì í™” í´ë˜ìŠ¤"""

    @staticmethod
    def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ìµœì í™”"""
        optimized_df = df.copy()

        for col in optimized_df.columns:
            col_type = optimized_df[col].dtype

            try:
                if col_type == 'object':
                    # ë²”ì£¼í˜• ë°ì´í„°ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                    if optimized_df[col].nunique() / len(optimized_df) < 0.5:
                        optimized_df[col] = optimized_df[col].astype('category')
                elif col_type == 'int64':
                    # ì •ìˆ˜ íƒ€ì… ë‹¤ìš´ìºìŠ¤íŒ…
                    col_min, col_max = optimized_df[col].min(), optimized_df[col].max()
                    if col_min >= 0:
                        if col_max < 256:
                            optimized_df[col] = optimized_df[col].astype('uint8')
                        elif col_max < 65536:
                            optimized_df[col] = optimized_df[col].astype('uint16')
                        elif col_max < 4294967296:
                            optimized_df[col] = optimized_df[col].astype('uint32')
                    else:
                        if col_min > -129 and col_max < 128:
                            optimized_df[col] = optimized_df[col].astype('int8')
                        elif col_min > -32769 and col_max < 32768:
                            optimized_df[col] = optimized_df[col].astype('int16')
                        elif col_min > -2147483649 and col_max < 2147483648:
                            optimized_df[col] = optimized_df[col].astype('int32')
                elif col_type == 'float64':
                    # ì‹¤ìˆ˜ íƒ€ì… ë‹¤ìš´ìºìŠ¤íŒ…
                    optimized_df[col] = optimized_df[col].astype('float32')
            except Exception as e:
                logger.warning(f"ì»¬ëŸ¼ {col} ìµœì í™” ì‹¤íŒ¨: {e}")
                continue

        return optimized_df

    @staticmethod
    def get_memory_usage_info(df: pd.DataFrame) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´"""
        memory_usage = df.memory_usage(deep=True)
        total_memory = memory_usage.sum()

        return {
            "total_memory_mb": total_memory / 1024 / 1024,
            "memory_per_column": {col: usage / 1024 / 1024 for col, usage in memory_usage.items()},
            "largest_column": memory_usage.idxmax(),
            "optimization_potential": MemoryOptimizer._calculate_optimization_potential(df)
        }

    @staticmethod
    def _calculate_optimization_potential(df: pd.DataFrame) -> str:
        """ìµœì í™” ì ì¬ë ¥ ê³„ì‚°"""
        try:
            original_memory = df.memory_usage(deep=True).sum()
            optimized_df = MemoryOptimizer.optimize_dataframe(df)
            optimized_memory = optimized_df.memory_usage(deep=True).sum()

            savings_percent = (original_memory - optimized_memory) / original_memory * 100

            if savings_percent > 30:
                return "high"
            elif savings_percent > 15:
                return "medium"
            else:
                return "low"
        except Exception:
            return "unknown"

class AnalysisCache:
    """ë¶„ì„ ê²°ê³¼ ìºì‹œ í´ë˜ìŠ¤"""

    def __init__(self, cache_dir: str = ".analysis_cache", max_age_hours: int = 24):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.max_age_hours = max_age_hours

    def get_cache_key(self, df_hash: str, analysis_type: str, params: Dict[str, Any]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        params_str = json.dumps(params, sort_keys=True)
        key = hashlib.md5(f"{df_hash}_{analysis_type}_{params_str}".encode()).hexdigest()
        return key

    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        cache_file = self.cache_dir / f"{key}.json"

        if not cache_file.exists():
            return None

        # ìºì‹œ íŒŒì¼ ë‚˜ì´ í™•ì¸
        file_age_hours = (time.time() - cache_file.stat().st_mtime) / 3600
        if file_age_hours > self.max_age_hours:
            cache_file.unlink()  # ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ
            return None

        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return None

    def set(self, key: str, data: Any):
        """ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        cache_file = self.cache_dir / f"{key}.json"
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, default=str)
        except Exception as e:
            logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def clear_expired(self):
        """ë§Œë£Œëœ ìºì‹œ íŒŒì¼ë“¤ ì •ë¦¬"""
        current_time = time.time()
        for cache_file in self.cache_dir.glob("*.json"):
            file_age_hours = (current_time - cache_file.stat().st_mtime) / 3600
            if file_age_hours > self.max_age_hours:
                cache_file.unlink()

class AdvancedCombinationsAnalyzer:
    """ê³ ê¸‰ ì¡°í•© ë¶„ì„ê¸° í´ë˜ìŠ¤"""

    def __init__(self, config: AnalysisConfig = None):
        self.config = config or AnalysisConfig()
        self.performance_monitor = PerformanceMonitor()
        self.memory_optimizer = MemoryOptimizer()
        self.cache = AnalysisCache(self.config.cache_dir) if self.config.enable_caching else None

    def _load_from_cache(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ"""
        if not self.config.enable_caching or not self.cache:
            return None
        return self.cache.get(key)

    def _save_to_cache(self, key: str, data: Any):
        """ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        if not self.config.enable_caching or not self.cache:
            return
        self.cache.set(key, data)

    def _split_types_advanced(self, df: pd.DataFrame) -> Tuple[List[str], List[str], List[str]]:
        """ê³ ê¸‰ ì»¬ëŸ¼ íƒ€ì… ë¶„ë¥˜ (ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜•, í…ìŠ¤íŠ¸í˜•)"""
        numeric_cols = []
        categorical_cols = []
        text_cols = []

        for col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                # ìˆ˜ì¹˜í˜•ì´ì§€ë§Œ ê³ ìœ ê°’ì´ ì ìœ¼ë©´ ë²”ì£¼í˜•ìœ¼ë¡œ ì·¨ê¸‰
                if df[col].nunique() <= self.config.max_cardinality:
                    categorical_cols.append(col)
                else:
                    numeric_cols.append(col)
            else:
                # ë¬¸ìì—´ íƒ€ì… ë¶„ì„
                if df[col].dtype == 'object':
                    unique_ratio = df[col].nunique() / len(df)
                    avg_length = df[col].astype(str).str.len().mean()

                    # ì§§ê³  ë°˜ë³µì ì¸ í…ìŠ¤íŠ¸ëŠ” ë²”ì£¼í˜•
                    if (unique_ratio <= 0.1 or
                        (avg_length < 20 and df[col].nunique() <= self.config.max_cardinality)):
                        categorical_cols.append(col)
                    else:
                        text_cols.append(col)
                else:
                    # ë‚ ì§œ, ë¶ˆë¦¬ì–¸ ë“± ë‹¤ë¥¸ íƒ€ì…
                    if df[col].nunique() <= self.config.max_cardinality:
                        categorical_cols.append(col)

        return numeric_cols, categorical_cols, text_cols

    def _value_counts_top(self, s: pd.Series, top_k: int = 20) -> List[Dict[str, Any]]:
        """ìƒìœ„ ê°’ ì¹´ìš´íŠ¸ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
        vc = s.astype("object").value_counts(dropna=False).head(top_k)
        total = len(s)

        result = []
        for k, v in vc.items():
            # ê²°ì¸¡ê°’ ì²˜ë¦¬
            display_value = str(k) if pd.notna(k) else "NaN"
            result.append({
                "value": display_value,
                "count": int(v),
                "ratio": float(v/total),
                "percentage": float(v/total * 100)
            })

        return result

    def _lift_table_parallel(self, df: pd.DataFrame, a: str, b: str, top_k: int = 20) -> List[Dict[str, Any]]:
        """ë³‘ë ¬ ì²˜ë¦¬ëœ Lift í…Œì´ë¸” ê³„ì‚°"""
        x = df[a].astype("object")
        y = df[b].astype("object")
        ct = pd.crosstab(x, y)

        total = ct.values.sum()
        if total == 0 or ct.shape[0] == 0 or ct.shape[1] == 0:
            return []

        # Lift ê³„ì‚° ìµœì í™”
        px = ct.sum(axis=1) / total
        py = ct.sum(axis=0) / total
        expected = np.outer(px.values, py.values) * total

        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        lift = ct.values / np.maximum(expected, 1e-9)

        rows = []
        xi = list(ct.index)
        yi = list(ct.columns)

        for i in range(ct.shape[0]):
            for j in range(ct.shape[1]):
                if ct.values[i,j] >= self.config.min_sample_size:  # ìµœì†Œ ìƒ˜í”Œ í¬ê¸° í•„í„°ë§
                    lift_val = float(lift[i,j])
                    if lift_val >= self.config.lift_threshold:  # Lift ì„ê³„ê°’ í•„í„°ë§
                        rows.append({
                            "a_val": str(xi[i]) if pd.notna(xi[i]) else "NaN",
                            "b_val": str(yi[j]) if pd.notna(yi[j]) else "NaN",
                            "count": int(ct.values[i,j]),
                            "lift": lift_val,
                            "expected": float(expected[i,j]),
                            "support": float(ct.values[i,j] / total)
                        })

        # ê°œì„ ëœ ì •ë ¬: Liftì™€ Supportì˜ ì¡°í•© ì ìˆ˜
        rows.sort(key=lambda r: (r["lift"] * np.log1p(r["count"]) * r["support"]), reverse=True)
        return rows[:top_k]

    def _correlation_analysis(self, df: pd.DataFrame, x: str, y: str) -> Dict[str, Any]:
        """ê³ ê¸‰ ìƒê´€ê´€ê³„ ë¶„ì„"""
        s1, s2 = df[x], df[y]

        # ì´ìƒì¹˜ ì²˜ë¦¬
        s1 = s1.replace([np.inf, -np.inf], np.nan)
        s2 = s2.replace([np.inf, -np.inf], np.nan)

        # ê²°ì¸¡ê°’ ì œê±°
        combined = pd.concat([s1, s2], axis=1).dropna()

        if len(combined) < self.config.min_sample_size:
            return {"error": "insufficient_data", "sample_size": len(combined)}

        # ë‹¤ì¤‘ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        pearson = combined.corr(method="pearson").iloc[0,1]
        spearman = combined.corr(method="spearman").iloc[0,1]

        # Kendall tau (ë” robustí•œ ìˆœìœ„ ìƒê´€ê³„ìˆ˜)
        kendall = combined.corr(method="kendall").iloc[0,1]

        # ìƒê´€ê³„ìˆ˜ì˜ ì‹ ë¢°ì„± í‰ê°€
        confidence = self._correlation_confidence(len(combined), max(abs(pearson), abs(spearman)))

        return {
            "pearson": float(pearson),
            "spearman": float(spearman),
            "kendall": float(kendall),
            "sample_size": len(combined),
            "confidence": confidence,
            "strength": self._interpret_correlation_strength(max(abs(pearson), abs(spearman)))
        }

    def _correlation_confidence(self, n: int, r: float) -> str:
        """ìƒê´€ê³„ìˆ˜ì˜ ì‹ ë¢°ì„± í‰ê°€"""
        # Fisher z-transformationì„ ì‚¬ìš©í•œ ëŒ€ëµì ì¸ ì‹ ë¢°ë„ ê³„ì‚°
        if n < 10:
            return "very_low"
        elif n < 30:
            return "low"
        elif n < 100:
            return "moderate"
        else:
            return "high"

    def _interpret_correlation_strength(self, r: float) -> str:
        """ìƒê´€ê³„ìˆ˜ ê°•ë„ í•´ì„"""
        abs_r = abs(r)
        if abs_r >= 0.8:
            return "very_strong"
        elif abs_r >= 0.6:
            return "strong"
        elif abs_r >= 0.4:
            return "moderate"
        elif abs_r >= 0.2:
            return "weak"
        else:
            return "very_weak"

    def _anova_analysis(self, df: pd.DataFrame, cat: str, num: str) -> Dict[str, Any]:
        """ê³ ê¸‰ ë¶„ì‚°ë¶„ì„"""
        s = df[[cat, num]].dropna()

        if s[cat].nunique() < 2 or len(s) < self.config.min_sample_size:
            return {"error": "insufficient_data"}

        groups = [g[num].values for _, g in s.groupby(cat)]
        overall = s[num].values

        # ê·¸ë£¹ë³„ í†µê³„
        group_stats = []
        for name, group in s.groupby(cat):
            group_stats.append({
                "category": str(name),
                "count": len(group),
                "mean": float(group[num].mean()),
                "std": float(group[num].std()),
                "min": float(group[num].min()),
                "max": float(group[num].max())
            })

        # ANOVA ê³„ì‚°
        grand_mean = overall.mean()
        ss_between = sum(len(g) * (g.mean() - grand_mean)**2 for g in groups)
        ss_within = sum(((g - g.mean())**2).sum() for g in groups)
        ss_total = ((overall - grand_mean)**2).sum()

        df_between = len(groups) - 1
        df_within = len(overall) - len(groups)
        df_total = len(overall) - 1

        ms_between = ss_between / df_between if df_between > 0 else 0
        ms_within = ss_within / df_within if df_within > 0 else 0

        f_stat = ms_between / ms_within if ms_within > 0 else 0
        eta2 = ss_between / ss_total if ss_total > 0 else 0

        # p-value ê³„ì‚° (F-ë¶„í¬)
        from scipy import stats
        p_value = 1 - stats.f.cdf(f_stat, df_between, df_within)

        return {
            "eta2": float(eta2),
            "f_statistic": float(f_stat),
            "p_value": float(p_value),
            "significant": p_value < 0.05,
            "group_stats": group_stats,
            "overall_stats": {
                "count": len(overall),
                "mean": float(grand_mean),
                "std": float(np.std(overall)),
                "min": float(np.min(overall)),
                "max": float(np.max(overall))
            }
        }

    def analyze_combinations_advanced(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ê³ ê¸‰ ì¡°í•© ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
        start_time = time.time()
        logger.info(f"ğŸ” ê³ ê¸‰ ì¡°í•© ë¶„ì„ ì‹œì‘... (ìƒ˜í”Œ: {len(df)}í–‰)")

        # ë°ì´í„° ìƒ˜í”Œë§ (í•„ìš”ì‹œ)
        if len(df) > self.config.sample_cap:
            logger.info(f"ğŸ“Š ë°ì´í„° ìƒ˜í”Œë§: {len(df)} â†’ {self.config.sample_cap}")
            df = df.sample(self.config.sample_cap, random_state=42)

        # ì»¬ëŸ¼ íƒ€ì… ë¶„ë¥˜
        num_cols, cat_cols, text_cols = self._split_types_advanced(df)

        logger.info(f"ğŸ“‹ ì»¬ëŸ¼ ë¶„ë¥˜ ì™„ë£Œ: ìˆ˜ì¹˜í˜• {len(num_cols)}ê°œ, ë²”ì£¼í˜• {len(cat_cols)}ê°œ, í…ìŠ¤íŠ¸ {len(text_cols)}ê°œ")

        # ë©”íƒ€ ì •ë³´
        report = {
            "meta": {
                "timestamp": time.time(),
                "rows": len(df),
                "columns": len(df.columns),
                "numeric_cols": num_cols,
                "categorical_cols": cat_cols,
                "text_cols": text_cols,
                "config": {
                    "max_cardinality": self.config.max_cardinality,
                    "top_k": self.config.top_k,
                    "correlation_threshold": self.config.correlation_threshold,
                    "lift_threshold": self.config.lift_threshold,
                    "eta2_threshold": self.config.eta2_threshold
                }
            }
        }

        # 1. ë‹¨ë³€ëŸ‰ ë¶„ì„
        logger.info("ğŸ“Š ë‹¨ë³€ëŸ‰ ë¶„ì„ ì¤‘...")
        univariate = {}
        for col in cat_cols:
            univariate[col] = self._value_counts_top(df[col], self.config.top_k)
        report["univariate"] = univariate

        # 2. ë²”ì£¼í˜•-ë²”ì£¼í˜• ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬)
        logger.info("ğŸ”— ë²”ì£¼í˜•-ë²”ì£¼í˜• ê´€ê³„ ë¶„ì„ ì¤‘...")
        cc_pairs = []
        if self.config.parallel_processing and len(cat_cols) >= 2:
            with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
                futures = []
                for a, b in combinations(cat_cols, 2):
                    futures.append(executor.submit(self._lift_table_parallel, df, a, b, self.config.top_k))

                for future in as_completed(futures):
                    result = future.result()
                    if result:
                        # ì»¬ëŸ¼ ìŒ ì •ë³´ ì¶”ê°€
                        a, b = result[0]['a_val'], result[0]['b_val']  # ì„ì‹œ ì²˜ë¦¬
                        cc_pairs.append({"cols": (a, b), "pairs": result})
        else:
            for a, b in combinations(cat_cols, 2):
                rows = self._lift_table_parallel(df, a, b, self.config.top_k)
                if rows:
                    cc_pairs.append({"cols": (a, b), "pairs": rows})

        cc_pairs.sort(key=lambda x: max(p["lift"] for p in x["pairs"]) if x["pairs"] else 0, reverse=True)
        report["catcat"] = cc_pairs[:self.config.top_k]

        # 3. ìˆ˜ì¹˜í˜•-ìˆ˜ì¹˜í˜• ë¶„ì„
        logger.info("ğŸ“ˆ ìˆ˜ì¹˜í˜•-ìˆ˜ì¹˜í˜• ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘...")
        nn_pairs = []
        for a, b in combinations(num_cols, 2):
            corr_result = self._correlation_analysis(df, a, b)
            if "error" not in corr_result:
                max_corr = max(abs(corr_result.get("pearson", 0)), abs(corr_result.get("spearman", 0)))
                if max_corr >= self.config.correlation_threshold:
                    nn_pairs.append({"cols": (a, b), **corr_result})

        nn_pairs.sort(key=lambda x: max(abs(x.get("pearson", 0)), abs(x.get("spearman", 0))), reverse=True)
        report["numnum"] = nn_pairs[:self.config.top_k]

        # 4. ë²”ì£¼í˜•-ìˆ˜ì¹˜í˜• ë¶„ì„
        logger.info("ğŸ“Š ë²”ì£¼í˜•-ìˆ˜ì¹˜í˜• ë¶„ì‚° ë¶„ì„ ì¤‘...")
        cn_pairs = []
        for cat in cat_cols:
            for num in num_cols:
                anova_result = self._anova_analysis(df, cat, num)
                if "error" not in anova_result and anova_result["eta2"] >= self.config.eta2_threshold:
                    cn_pairs.append({"cols": (cat, num), **anova_result})

        cn_pairs.sort(key=lambda x: x["eta2"], reverse=True)
        report["catnum"] = cn_pairs[:self.config.top_k]

        # 5. í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¶„ì„ (ì„ íƒì )
        if text_cols:
            logger.info("ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¶„ì„ ì¤‘...")
            text_analysis = {}
            for col in text_cols:
                text_stats = self._analyze_text_column(df[col])
                text_analysis[col] = text_stats
            report["text_analysis"] = text_analysis

        # 6. ì‹œê°í™” ì¶”ì²œ
        logger.info("ğŸ¨ ì‹œê°í™” ì¶”ì²œ ìƒì„± ì¤‘...")
        report["visualization_recommendations"] = self._suggest_advanced_plots(report)

        # 7. ìš”ì•½ í†µê³„
        report["summary"] = {
            "total_relationships_found": len(cc_pairs) + len(nn_pairs) + len(cn_pairs),
            "strong_correlations": len([p for p in nn_pairs if p.get("strength") in ["strong", "very_strong"]]),
            "significant_anova": len([p for p in cn_pairs if p.get("significant", False)]),
            "high_lift_associations": len([p for p in cc_pairs if any(pair["lift"] >= 2.0 for pair in p["pairs"])]),
            "processing_time": time.time() - start_time
        }

        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ! ì´ {report['summary']['total_relationships_found']}ê°œ ê´€ê³„ ë°œê²¬")
        return report

    def _analyze_text_column(self, series: pd.Series) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¶„ì„"""
        text_data = series.astype(str)

        return {
            "total_entries": len(text_data),
            "unique_entries": text_data.nunique(),
            "avg_length": float(text_data.str.len().mean()),
            "max_length": int(text_data.str.len().max()),
            "empty_count": int(text_data.str.strip().eq('').sum()),
            "null_count": int(series.isna().sum()),
            "most_common_words": self._extract_common_words(text_data)
        }

    def _extract_common_words(self, text_series: pd.Series, top_n: int = 10) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ ì¶”ì¶œ"""
        from collections import Counter
        import re

        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        all_text = ' '.join(text_series.dropna().astype(str))
        words = re.findall(r'\b\w+\b', all_text.lower())

        # ë¶ˆìš©ì–´ í•„í„°ë§ (ê°„ë‹¨ ë²„ì „)
        stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were'}
        filtered_words = [word for word in words if word not in stopwords and len(word) > 2]

        word_counts = Counter(filtered_words)
        return [{"word": word, "count": count} for word, count in word_counts.most_common(top_n)]

    def _suggest_advanced_plots(self, report: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê³ ê¸‰ ì‹œê°í™” ì¶”ì²œ"""
        recommendations = []

        # ë²”ì£¼í˜•-ë²”ì£¼í˜• ê´€ê³„
        for entry in report.get("catcat", [])[:5]:
            cols = entry["cols"]
            max_lift = max(pair["lift"] for pair in entry["pairs"])
            recommendations.append({
                "type": "heatmap",
                "cols": list(cols),
                "priority": "high" if max_lift >= 2.0 else "medium",
                "reason": ".2f",
                "insights": self._generate_insights("catcat", entry)
            })

        # ìˆ˜ì¹˜í˜•-ìˆ˜ì¹˜í˜• ê´€ê³„
        for entry in report.get("numnum", [])[:5]:
            cols = entry["cols"]
            strength = entry.get("strength", "weak")
            recommendations.append({
                "type": "scatter",
                "cols": list(cols),
                "priority": "high" if strength in ["strong", "very_strong"] else "medium",
                "reason": f"Strong {strength} correlation ({entry.get('pearson', 0):.2f})",
                "insights": self._generate_insights("numnum", entry)
            })

        # ë²”ì£¼í˜•-ìˆ˜ì¹˜í˜• ê´€ê³„
        for entry in report.get("catnum", [])[:5]:
            cols = entry["cols"]
            significant = entry.get("significant", False)
            recommendations.append({
                "type": "boxplot",
                "cols": list(cols),
                "priority": "high" if significant else "medium",
                "reason": f"Significant group differences (Î·Â² = {entry.get('eta2', 0):.3f})",
                "insights": self._generate_insights("catnum", entry)
            })

        return recommendations

    def _generate_insights(self, analysis_type: str, entry: Dict[str, Any]) -> List[str]:
        """ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []

        if analysis_type == "catcat":
            max_lift = max(pair["lift"] for pair in entry["pairs"])
            if max_lift >= 3.0:
                insights.append("ë§¤ìš° ê°•í•œ ì—°ê´€ì„±ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤")
            elif max_lift >= 2.0:
                insights.append("ê°•í•œ ì—°ê´€ì„±ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤")
            else:
                insights.append("ì•½í•œ ì—°ê´€ì„±ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤")

        elif analysis_type == "numnum":
            strength = entry.get("strength", "weak")
            if strength == "very_strong":
                insights.append("ë§¤ìš° ê°•í•œ ì„ í˜• ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤")
            elif strength == "strong":
                insights.append("ê°•í•œ ì„ í˜• ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤")
            else:
                insights.append("ì•½í•œ ì„ í˜• ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤")

        elif analysis_type == "catnum":
            if entry.get("significant", False):
                insights.append("ê·¸ë£¹ ê°„ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤")
            else:
                insights.append("ê·¸ë£¹ ê°„ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        return insights

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í•¨ìˆ˜ë“¤
def _split_types(df, max_cardinality=50):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    analyzer = AdvancedCombinationsAnalyzer()
    num_cols, cat_cols, _ = analyzer._split_types_advanced(df)
    return num_cols, cat_cols

class AdvancedCombinationsAnalyzer:
    def __init__(self):
        pass

    def _value_counts_top(self, s, top_k=20):
        raise NotImplementedError

def _value_counts_top(s: pd.Series, top_k=20):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    analyzer = AdvancedCombinationsAnalyzer()
    return analyzer._value_counts_top(s, top_k)

def _lift_table(df, a, b, top_k=20):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    analyzer = AdvancedCombinationsAnalyzer()
    return analyzer._lift_table_parallel(df, a, b, top_k)

def _pearson_spearman(df, x, y, method="pearson"):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    analyzer = AdvancedCombinationsAnalyzer()
    result = analyzer._correlation_analysis(df, x, y)
    if method == "spearman":
        return result.get("spearman")
    else:
        return result.get("pearson")

def _anova_eta2(df, cat, num):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    analyzer = AdvancedCombinationsAnalyzer()
    result = analyzer._anova_analysis(df, cat, num)
    return result.get("eta2")

def analyze_combinations(df: pd.DataFrame, *, max_cardinality=50, top_k=20, sample_cap=200_000):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    config = AnalysisConfig(
        max_cardinality=max_cardinality,
        top_k=top_k,
        sample_cap=sample_cap
    )
    analyzer = AdvancedCombinationsAnalyzer(config)
    return analyzer.analyze_combinations_advanced(df)

def suggest_plots(report):
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    analyzer = AdvancedCombinationsAnalyzer()
    return analyzer._suggest_advanced_plots(report)
