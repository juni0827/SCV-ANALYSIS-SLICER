
# dsl2code.py
# Convert DSL token sequence (e.g., ["C1", "C2", "C6"]) to executable Python code

token_code_map = {
    "C1": "df.describe()",
    "C2": "df.info()",
    "C3": "df.isnull().sum()",
    "C4": "df.dtypes",
    "C5": "df.nunique()",
    "C6": "df.head()",
    "C7": "df.tail()",
    "C8": "df.corr()",
    "C9": "df.columns",
    "C10": "df.memory_usage()",
    "C11": "(df.isnull().sum() / len(df) * 100).round(2)",  # ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)
    "C12": "import seaborn as sns; import matplotlib.pyplot as plt; sns.heatmap(df.corr(), annot=True); plt.show()",  # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    "C13": "print(df[df.columns[0]].value_counts())",  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê°’ë³„ ê°œìˆ˜
    "C14": "df.describe(include='all')",
    "C15": "df.shape",
    "C16": "df.duplicated().sum()",
    "C17": "df.sample(10)",
    "C18": "{col: df[col].unique() for col in df.columns}",
    "C19": "df.T",
    "C20": "df.index"
    ,
    "C21": "df[df.isnull().any(axis=1)]",  # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰
    "C22": "{col: df[col].mode().tolist() for col in df.columns}",  # ê° ì»¬ëŸ¼ë³„ ìµœë¹ˆê°’
    "C23": "import matplotlib.pyplot as plt; df.select_dtypes(include='number').hist(figsize=(10,8)); plt.show()",  # ìˆ˜ì¹˜í˜• íˆìŠ¤í† ê·¸ë¨
    "C24": "[df[col].value_counts().head() for col in df.select_dtypes(include='object').columns]",  # ìƒìœ„ 5ê°œ ë²”ì£¼í˜• ì»¬ëŸ¼ ê°’ë³„ ê°œìˆ˜
    "C25": "df.corr().unstack().sort_values(ascending=False)[len(df.columns):len(df.columns)+5]",  # ìƒê´€ê³„ìˆ˜ ìƒìœ„ 5ê°œ
    "C26": "df.groupby(df.columns[0]).mean()",  # ì²« ì»¬ëŸ¼ ê¸°ì¤€ ê·¸ë£¹ë³„ í‰ê· 
    "C27": "df.to_excel('output.xlsx', index=False)",  # ì—‘ì…€ ì €ì¥
    "C28": "df.to_json('output.json', orient='records')",  # json ì €ì¥
    "C29": "df.std()",  # í‘œì¤€í¸ì°¨
    "C30": "{col: (df[col].min(), df[col].max()) for col in df.columns}",  # ìµœëŒ€/ìµœì†Œê°’
    "C31": "(df==0).all(axis=1).sum()",  # ëª¨ë“  ê°’ì´ 0ì¸ í–‰ ê°œìˆ˜
    "C32": "df.duplicated(keep=False).sum()",  # ëª¨ë“  ê°’ì´ ì¤‘ë³µì¸ í–‰ ê°œìˆ˜
    "C33": "df.count()",  # ê²°ì¸¡ì¹˜ê°€ ì•„ë‹Œ ê°’ ê°œìˆ˜
    "C34": "df.index.nunique()",  # ê³ ìœ  ì¸ë±ìŠ¤ ê°œìˆ˜
    "C35": "import seaborn as sns; import matplotlib.pyplot as plt; sns.pairplot(df.select_dtypes(include='number')); plt.show()",  # pairplot
    "C36": "df.sort_values(by=df.columns[0], ascending=True)",  # ì²« ì»¬ëŸ¼ ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ
    "C37": "df.sort_values(by=df.columns[0], ascending=False)",  # ì²« ì»¬ëŸ¼ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
    "C38": "df.memory_usage(deep=True).sum() / 1024**2",  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(MB)
    "C39": "pd.DataFrame({'col': df.columns, 'dtype': df.dtypes, 'nulls': df.isnull().sum()})",  # ì»¬ëŸ¼ëª…, íƒ€ì…, ê²°ì¸¡ì¹˜
    "C40": "(df<0).all(axis=1).sum()",  # ëª¨ë“  ê°’ì´ ìŒìˆ˜ì¸ í–‰ ê°œìˆ˜
    
    # ê³ ê¸‰ ë¶„ì„ í† í° (C41-C50)
    "C41": "df.skew(numeric_only=True)",  # ì™œë„ (ë¹„ëŒ€ì¹­ë„)
    "C42": "df.kurtosis(numeric_only=True)",  # ì²¨ë„
    "C43": "df.quantile([0.25, 0.5, 0.75])",  # ì‚¬ë¶„ìœ„ìˆ˜
    "C44": "df.select_dtypes(include='number').apply(lambda x: x.value_counts().head())",  # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìµœë¹ˆê°’
    "C45": "{col: df[col].nunique()/len(df)*100 for col in df.columns}",  # ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ë¹„ìœ¨(%)
    "C46": "df.apply(lambda x: sum(x.duplicated()))",  # ì»¬ëŸ¼ë³„ ì¤‘ë³µê°’ ê°œìˆ˜
    "C47": "import matplotlib.pyplot as plt; df.boxplot(figsize=(12,6)); plt.xticks(rotation=45); plt.show()",  # ë°•ìŠ¤í”Œë¡¯
    "C48": "df.columns[df.isnull().any()].tolist()",  # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ ëª©ë¡
    "C49": "pd.crosstab(df.iloc[:,0], df.iloc[:,1]) if len(df.columns) >= 2 else 'Need at least 2 columns'",  # êµì°¨í‘œ
    "C50": "from src.core.combinations import AdvancedCombinationsAnalyzer; AdvancedCombinationsAnalyzer().analyze_all_combinations(df)",  # ì¡°í•© ë¶„ì„
    
    # íŠ¹ìˆ˜ ê¸°ëŠ¥ í† í°
    "SAVE": "save_results",  # ê²°ê³¼ ì €ì¥ íŠ¸ë¦¬ê±°
    "EXPORT": "df.to_csv('analyzed_data.csv', index=False)",  # CSV ë‚´ë³´ë‚´ê¸°
    "PROFILE": "df.profile_report() if 'profile_report' in dir(df) else print('pandas_profiling not available')",  # í”„ë¡œíŒŒì¼ë§
}

def dsl_to_code(dsl_sequence, csv_path="your_file.csv"):
    """Convert a sequence of DSL tokens into executable Python code.

    Parameters
    ----------
    dsl_sequence : list[str]
        Ordered DSL tokens such as ["C1", "C2"].
    csv_path : str, optional
        Path to the CSV file that should be read in the generated code.
        Defaults to "your_file.csv" for backward compatibility.
    """
    # í—¤ë” ìƒì„±
    lines = [
        "#!/usr/bin/env python3",
        '"""',
        f'ìë™ ìƒì„±ëœ ë°ì´í„° ë¶„ì„ ì½”ë“œ',
        f'DSL ì‹œí€€ìŠ¤: {" â†’ ".join(dsl_sequence)}',
        f'ìƒì„± ì‹œê°„: {_get_timestamp()}',
        '"""',
        "",
        "import pandas as pd",
        "import numpy as np",
        ""
    ]
    
    # íŒŒì¼ ë¡œë”© ë° ê¸°ë³¸ í™•ì¸
    lines.extend([
        "# ë°ì´í„° ë¡œë”©",
        f"print('ğŸ“‚ ë°ì´í„° ë¡œë”©: {csv_path}')",
        f"df = pd.read_csv({repr(csv_path)})",
        f"print(f'âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {{len(df):,}}í–‰ Ã— {{len(df.columns)}}ì—´')",
        ""
    ])
    
    # ê° í† í°ì— ëŒ€í•œ ì½”ë“œ ìƒì„±
    for i, token in enumerate(dsl_sequence, 1):
        code_line = token_code_map.get(token)
        if code_line:
            lines.extend([
                f"# {i}. ë¶„ì„: {token}",
                f"print('\\n=== {token}: {_get_token_description(token)} ===')",
                "try:",
                f"    result_{i} = {code_line}",
                f"    print(result_{i})",
                "except Exception as e:",
                f"    print(f'âŒ {token} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {{e}}')",
                ""
            ])
    
    # í‘¸í„° ì¶”ê°€
    lines.extend([
        "print('\\nğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!')",
        f"print('ğŸ“Š ì´ {len(dsl_sequence)}ê°œì˜ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.')"
    ])
    
    return "\n".join(lines)

def _get_timestamp():
    """í˜„ì¬ ì‹œê°„ ë°˜í™˜"""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def _get_token_description(token):
    """í† í° ì„¤ëª… ë°˜í™˜"""
    descriptions = {
        "C1": "ê¸°ìˆ í†µê³„ ìš”ì•½",
        "C2": "ë°ì´í„° ì •ë³´",
        "C3": "ê²°ì¸¡ì¹˜ ê°œìˆ˜",
        "C4": "ë°ì´í„° íƒ€ì…",
        "C5": "ê³ ìœ ê°’ ê°œìˆ˜",
        "C6": "ìƒìœ„ 5í–‰",
        "C7": "í•˜ìœ„ 5í–‰",
        "C8": "ìƒê´€ê´€ê³„ í–‰ë ¬",
        "C9": "ì»¬ëŸ¼ ëª©ë¡",
        "C10": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰",
        "C11": "ê²°ì¸¡ì¹˜ ë¹„ìœ¨",
        "C12": "ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ",
        "C13": "ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê°’ ë¶„í¬",
        "C14": "ì „ì²´ ê¸°ìˆ í†µê³„",
        "C15": "ë°ì´í„° í¬ê¸°",
        "C16": "ì¤‘ë³µí–‰ ê°œìˆ˜",
        "C17": "ëœë¤ ìƒ˜í”Œ 10ê°œ",
        "C18": "ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’",
        "C19": "ë°ì´í„° ì „ì¹˜",
        "C20": "ì¸ë±ìŠ¤ ì •ë³´",
        "C21": "ê²°ì¸¡ì¹˜ í¬í•¨ í–‰",
        "C22": "ê° ì»¬ëŸ¼ë³„ ìµœë¹ˆê°’",
        "C23": "ìˆ˜ì¹˜í˜• íˆìŠ¤í† ê·¸ë¨",
        "C24": "ë²”ì£¼í˜• ê°’ ë¶„í¬",
        "C25": "ìƒê´€ê³„ìˆ˜ ìƒìœ„ 5ê°œ",
        "C26": "ì²« ì»¬ëŸ¼ ê¸°ì¤€ ê·¸ë£¹ë³„ í‰ê· ",
        "C27": "ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥",
        "C28": "JSON íŒŒì¼ë¡œ ì €ì¥",
        "C29": "í‘œì¤€í¸ì°¨",
        "C30": "ìµœëŒ€/ìµœì†Œê°’",
        "C31": "ëª¨ë“  ê°’ì´ 0ì¸ í–‰",
        "C32": "ì¤‘ë³µ í–‰ ê°œìˆ˜",
        "C33": "ìœ íš¨ê°’ ê°œìˆ˜",
        "C34": "ê³ ìœ  ì¸ë±ìŠ¤ ê°œìˆ˜",
        "C35": "ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°„ ê´€ê³„ë„",
        "C36": "ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬",
        "C37": "ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬",
        "C38": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(MB)",
        "C39": "ì»¬ëŸ¼ ì •ë³´ ìš”ì•½",
        "C40": "ìŒìˆ˜ê°’ í–‰ ê°œìˆ˜",
        "C41": "ì™œë„ ë¶„ì„",
        "C42": "ì²¨ë„ ë¶„ì„",
        "C43": "ì‚¬ë¶„ìœ„ìˆ˜",
        "C44": "ìˆ˜ì¹˜í˜• ìµœë¹ˆê°’",
        "C45": "ê³ ìœ ê°’ ë¹„ìœ¨",
        "C46": "ì»¬ëŸ¼ë³„ ì¤‘ë³µê°’",
        "C47": "ë°•ìŠ¤í”Œë¡¯ ì‹œê°í™”",
        "C48": "ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ ëª©ë¡",
        "C49": "êµì°¨í‘œ ë¶„ì„",
        "C50": "ì¡°í•© ë¶„ì„",
        "SAVE": "ê²°ê³¼ ì €ì¥",
        "EXPORT": "CSV ë‚´ë³´ë‚´ê¸°",
        "PROFILE": "ë°ì´í„° í”„ë¡œíŒŒì¼ë§"
    }
    return descriptions.get(token, "ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ì„")

def generate_analysis_template(analysis_type="basic"):
    """ë¶„ì„ í…œí”Œë¦¿ ìƒì„±"""
    templates = {
        "basic": ["C2", "C15", "C6", "C3", "C1"],
        "statistical": ["C1", "C14", "C29", "C41", "C42", "C43"],
        "visualization": ["C12", "C23", "C35", "C47"],
        "missing_data": ["C3", "C11", "C21", "C48"],
        "correlation": ["C8", "C12", "C25", "C50"],
        "comprehensive": ["C2", "C15", "C3", "C1", "C8", "C12", "C23", "C50"]
    }
    return templates.get(analysis_type, templates["basic"])

# ì‚¬ìš© ì˜ˆì‹œ:
# basic_analysis = generate_analysis_template("basic")
# code = dsl_to_code(basic_analysis, "data.csv")
# print(code)
